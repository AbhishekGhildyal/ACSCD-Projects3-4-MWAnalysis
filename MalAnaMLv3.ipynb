{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7676, 9)\n",
      "   Files Deleted  Files Created  Files Written  Directories Created  \\\n",
      "0              0              0              0                    0   \n",
      "1              0              6              4                    8   \n",
      "2              8              6              7                   15   \n",
      "3              0              0              0                    1   \n",
      "4              5             71             70                   11   \n",
      "\n",
      "   Opened REG keys  DLLs Loaded  Hosts  VirusTotal  \n",
      "0                0            3      0           0  \n",
      "1              277           19      4           0  \n",
      "2              309           74      0           0  \n",
      "3              185           15      0           0  \n",
      "4              524           49      0           0  \n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "df =  pd.read_csv('Documents/DAFeatures_Train.csv')\n",
    "print(df.shape)\n",
    "df.describe()\n",
    "\n",
    "#create a dataframe with all training data except the target column\n",
    "X_train = df.drop(columns=['File Type'])\n",
    "\n",
    "#check that the target variable has been removed\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   File Type\n",
      "0          6\n",
      "1          1\n",
      "2          6\n",
      "3          6\n",
      "4          6\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe with only the target column\n",
    "y_train = df[['File Type']]\n",
    "\n",
    "#view dataframe\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#one-hot encode target column\n",
    "y_train = to_categorical(df['File Type'])\n",
    "\n",
    "#vcheck that target column has been converted\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Train on 6140 samples, validate on 1536 samples\n",
      "Epoch 1/30\n",
      "6140/6140 [==============================] - 5s 839us/step - loss: 1.0632 - accuracy: 0.7883 - val_loss: 0.8552 - val_accuracy: 0.8737\n",
      "Epoch 2/30\n",
      "6140/6140 [==============================] - 2s 299us/step - loss: 0.6092 - accuracy: 0.8749 - val_loss: 0.5981 - val_accuracy: 0.8822\n",
      "Epoch 3/30\n",
      "6140/6140 [==============================] - 2s 339us/step - loss: 0.4190 - accuracy: 0.8883 - val_loss: 0.3159 - val_accuracy: 0.9069\n",
      "Epoch 4/30\n",
      "6140/6140 [==============================] - 2s 343us/step - loss: 0.3266 - accuracy: 0.9029 - val_loss: 0.2899 - val_accuracy: 0.9128\n",
      "Epoch 5/30\n",
      "6140/6140 [==============================] - 2s 345us/step - loss: 0.3156 - accuracy: 0.9098 - val_loss: 0.2588 - val_accuracy: 0.9095\n",
      "Epoch 6/30\n",
      "6140/6140 [==============================] - 2s 392us/step - loss: 0.2871 - accuracy: 0.9129 - val_loss: 0.2781 - val_accuracy: 0.9232\n",
      "Epoch 7/30\n",
      "6140/6140 [==============================] - 2s 358us/step - loss: 0.4072 - accuracy: 0.9067 - val_loss: 0.3098 - val_accuracy: 0.9069\n",
      "Epoch 8/30\n",
      "6140/6140 [==============================] - 2s 373us/step - loss: 0.3205 - accuracy: 0.9187 - val_loss: 0.2354 - val_accuracy: 0.9180\n",
      "Epoch 9/30\n",
      "6140/6140 [==============================] - 2s 350us/step - loss: 0.2563 - accuracy: 0.9235 - val_loss: 0.3944 - val_accuracy: 0.9232\n",
      "Epoch 10/30\n",
      "6140/6140 [==============================] - 2s 368us/step - loss: 0.2450 - accuracy: 0.9257 - val_loss: 0.2383 - val_accuracy: 0.9342\n",
      "Epoch 11/30\n",
      "6140/6140 [==============================] - 2s 366us/step - loss: 0.2506 - accuracy: 0.9295 - val_loss: 0.3856 - val_accuracy: 0.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8efc635490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#get number of columns in training data\n",
    "n_cols = X_train.shape[1]\n",
    "print (n_cols)\n",
    "\n",
    "#add model layers\n",
    "model.add(Dense(200, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "#model.add(Dense(7))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9314747452735901% \n",
      " Error on training data: 0.06852525472640991\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    "\n",
    "model.save('MalDA.model')\n",
    "\n",
    " \n",
    "#pred_test= model.predict(X_test)\n",
    "#scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "(2562, 8)\n",
      "Accuracy on test data: 0.931693971157074% \n",
      " Error on test data: 0.06830602884292603\n",
      "[6 6 4 6 4 3 6 6 3 1 2 6 6 4 4 5 6 5 6 4 6 6 6 6 5 6 6 0 6 6]\n"
     ]
    }
   ],
   "source": [
    "#example on how to use our newly trained model on how to make predictions on unseen data (we will pretend our new data is saved in a dataframe called 'test_X').\n",
    "test_file =  pd.read_csv('Documents/DAFeatures_Test.csv')\n",
    "X_test = test_file.drop(columns=['File Type'])\n",
    "\n",
    "#one-hot encode target column\n",
    "y_test = to_categorical(test_file['File Type'])\n",
    "\n",
    "#vcheck that target column has been converted\n",
    "print(y_test[0:30])\n",
    "\n",
    "print(X_test.shape)\n",
    "pred_test= model.predict_classes(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))  \n",
    "\n",
    "print(pred_test[0:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
